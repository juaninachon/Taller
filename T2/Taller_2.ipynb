{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistencia interna\n",
    "\n",
    "¡Buenas! En esta segunda actividad vamos a aplicar el alfa de Cronbach en 2 escalas que integran el cuestionario que completan las familias que participan del proyecto: El _cuestionario de la conducta infantil (CBQ)_ y la _escala de confusión, barullo y orden (CHAOS)_.\n",
    "La implementación se puede hacer tanto en **R** como en **Python**. En caso de querer hacer el paso a paso usando ambos lenguajes, sugiero que prueben [Quarto](https://quarto.org/). Los archivos de este programa (.qmd), que se pueden correr tanto desde R Studio como de VS Code, funcionan de manera muy parecida a Jupyter notebooks, combinando Markdown con celdas de código. La diferencia principal está en que se pueden invocar celdas de distintos lenguajes en la misma ventana sin tener que alternar el kernel.\n",
    "\n",
    "Las preguntas guía van a ser estas: ¿Creen que los ítems que componen cada escala/subescala refieren a constructos unidimensionales? Es decir, ¿podemos asumir que están midiendo el mismo y único rasgo subyacente? ¿Cómo podemos verificar si hay ítems que se comportan distinto al resto?\n",
    "\n",
    "Recordemos los 3 pasos fundamentales de la ciencia de datos:\n",
    "\n",
    "1. Organizar los datos - **Selección y ordenamiento de la información**\n",
    "2. Explorar y visualizar la información - **Análisis descriptivo**\n",
    "3. Prueba de hipótesis - **Análisis inferencial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso uno: Leer el .csv, reeplazar los valores de cadena de caracteres por valores escalares y segmentar la base por escala/subescala. \n",
    "\n",
    "CHAOS: \"Desconoce o prefiere no responder\" = NA, \"Nunca\" = 1 , \"Ocasionalmente\" = 2, \"Con bastante frecuencia\" = 3, \"Siempre\" = 4 \\\n",
    "\\\n",
    "CBQ: \"No aplicable (la situación no tuvo lugar en los últimos 6 meses), desconoce o prefiere no responder\" = NA, \"Falso en extremo\" = 1, \"Bastante falso\" = 2, \"Ligeramente falso\" = 3, \"Ni falso ni verdadero\" = 4, \"Ligeramente Cierto\" = 5, \"Bastante Cierto\" = 6, \"Cierto en Extremo\" = 7\n",
    "\n",
    "\n",
    "**¡Cuidado con los ítems invertidos!** Leer y ajustar para que cada uno apunte en el sentido conceptual correcto \\\n",
    "![](cbq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso dos: Crear matrices de correlación (cualquier método) entre los ítems de cada escala/subescala. \n",
    "Ejemplo de Gráfico con colores/heatmap: \\\n",
    "![](cormap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso tres: Calcular el alfa con sus intervalos de confianza al 95% y el coeficiente ajustado por eliminación de ítems. \n",
    "Paquetes sugeridos para **R** y **Python**: _psych_ y _pingouin_, respectivamente. \\\n",
    "¿Qué escalas/subescalas demuestran un nivel de consistencia interna aceptable? En cada caso, ¿qué ítems se podrían eliminar para mejorar sustancialmente los coeficientes? Justificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
